---
title: "PBSR Assignment 2"
author: "Shreyam Banerjee, Dipanjoy Saha, Richik Chakraborty"
date: "2022-11-17"
output:
  word_document: default
  html_document: default
  pdf_document: default
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.align = 'center')
knitr::opts_chunk$set(fig = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```













```{r}
library(tidyverse)
```

## Question 2

```{r warning=FALSE}
mle <- function(log_alpha, data, sigma) {
  l = sum(log(dgamma(data, shape = exp(log_alpha), scale = sigma)))
  return(-l)
}
MyMLE <- function(data, sigma) {
  log_alpha_initial <- log(mean(data)^2/var(data))
  estimator <- optim(log_alpha_initial,
                     mle,
                     data = data,
                     sigma = sigma)
  log_alpha_hat <- estimator$par
  return(log_alpha_hat)
}
```


```{r warning=FALSE}
get_estimates <- function(n, alpha, sigma) {
  estimates <- c()
  for (i in 1:1000) {
    samples <- rgamma(n, shape = alpha, scale = sigma)
    estimates <- append(estimates, MyMLE(data = samples, sigma = sigma))
  }
  return(estimates)
}
```


```{r warning=FALSE}
n = 20
alpha = 1.5
sigma = 2.2
estimated_mle <- tibble(get_estimates(n = n, alpha = alpha, sigma = sigma))
colnames(estimated_mle) <- c("estimate")
perc_2.5 <- quantile(estimated_mle$estimate, probs = 0.025, names = FALSE)
perc_97.5 <- quantile(estimated_mle$estimate, probs = 0.975, names = FALSE)
estimated_mle %>% 
  ggplot(aes(estimate)) +
  geom_histogram(color = "black", fill = "yellow") +
  geom_vline(xintercept = log(alpha), 
             size = 2,
             linetype = "dashed") +
  annotate("text", label = "Actual log(alpha)", x = 0.5, y = 95, color = "black") +
  geom_vline(xintercept = perc_2.5, 
             color = "#00B9FF", size = 1.5, linetype = "dashed") +
  annotate("text", label = "2.5 percentile", x = perc_2.5 + 0.1, y = 95, color = "#00B9FF") +
  geom_vline(xintercept = perc_97.5, 
             color = "#E08304", size = 1.5, linetype = "dashed") +
  annotate("text", label = "97.5 percentile", x = perc_97.5 + 0.1, y = 95, color = "#E08304") +
  labs(title = paste("n = ", n, ", alpha = ", alpha, ", sigma = ", sigma),
       x = "Estimated MLE",
       y = "Count")
diff_20 <- perc_97.5 - perc_2.5
```


```{r warning=FALSE}
n = 40
alpha = 1.5
sigma = 2.2
estimated_mle <- tibble(get_estimates(n = n, alpha = alpha, sigma = sigma))
colnames(estimated_mle) <- c("estimate")
perc_2.5 <- quantile(estimated_mle$estimate, probs = 0.025, names = FALSE)
perc_97.5 <- quantile(estimated_mle$estimate, probs = 0.975, names = FALSE)
estimated_mle %>% 
  ggplot(aes(estimate)) +
  geom_histogram(color = "black", fill = "yellow") +
  geom_vline(xintercept = log(alpha), 
             size = 2,
             linetype = "dashed") +
  annotate("text", label = "Actual log(alpha)", x = log(alpha) + 0.1, y = 95, color = "black") +
  geom_vline(xintercept = perc_2.5, 
             color = "#00B9FF", size = 1.5, linetype = "dashed") +
  annotate("text", label = "2.5 percentile", x = perc_2.5 + 0.1, y = 95, color = "#00B9FF") +
  geom_vline(xintercept = perc_97.5, 
             color = "#E08304", size = 1.5, linetype = "dashed") +
  annotate("text", label = "97.5 percentile", x = perc_97.5 + 0.1, y = 95, color = "#E08304") +
  labs(title = paste("n = ", n, ", alpha = ", alpha, ", sigma = ", sigma),
       x = "Estimated MLE",
       y = "Count")
diff_40 <- perc_97.5 - perc_2.5
```


```{r}
n = 100
alpha = 1.5
sigma = 2.2
estimated_mle <- tibble(get_estimates(n = n, alpha = alpha, sigma = sigma))
colnames(estimated_mle) <- c("estimate")
perc_2.5 <- quantile(estimated_mle$estimate, probs = 0.025, names = FALSE)
perc_97.5 <- quantile(estimated_mle$estimate, probs = 0.975, names = FALSE)
estimated_mle %>% 
  ggplot(aes(estimate)) +
  geom_histogram(color = "black", fill = "yellow") +
  geom_vline(xintercept = log(alpha), 
             size = 2,
             linetype = "dashed") +
  annotate("text", label = "Actual log(alpha)", x = log(alpha) + 0.05, y = 95, color = "black") +
  geom_vline(xintercept = perc_2.5, 
             color = "#00B9FF", size = 1.5, linetype = "dashed") +
  annotate("text", label = "2.5 percentile", x = perc_2.5 + 0.05, y = 95, color = "#00B9FF") +
  geom_vline(xintercept = perc_97.5, 
             color = "#E08304", size = 1.5, linetype = "dashed") +
  annotate("text", label = "97.5 percentile", x = perc_97.5 + 0.05, y = 95, color = "#E08304") +
  labs(title = paste("n = ", n, ", alpha = ", alpha, ", sigma = ", sigma),
       x = "Estimated MLE",
       y = "Count")
diff_100 <- perc_97.5 - perc_2.5
```

```{r}
diff_20
diff_40
diff_100
```
Thus we can see from the the plot that as the sample size increases, the gap between the percentile points keep on decreasing.


# Problem 3

```{r}
library(tidyverse)
library(scales)
```

```{r}
data_q3 <- faithful %>% 
  as_tibble()
x <- sort(data_q3$waiting)
# hist(x, xlab = 'waiting', probability = T, col='pink', main='')
```

comparing 3 models

```{r}
# model 1
p <- length(x[x<65])/length(x)
as <- mean(x[x<65])
ass <- var(x[x<65])
s <- ass/as
a <- as/s
mu <- mean(x[x>=65])
sigma <- sd(x[x>=65])
theta_inital <- c(p, a, s, mu, sigma)
neg_log_likelihood <- function(theta, data){
  n = length(data)
  
  p = theta[1]
  a = theta[2]
  s = theta[3]
  mu = theta[4]
  sigma = theta[5]
  
  l = 0
  for (i in 1:n) {
    l = l + log(p*dgamma(data[i], shape = a, scale = s) + (1-p)*dnorm(data[i], mean = mu, sd = sigma))
  }
  return(-l)
}
fit = optim(theta_inital,
            neg_log_likelihood,
            data = x,
            control = list(maxit = 1500),
            lower = c(0, 0, 0, -Inf, 0),
            upper = c(1, Inf, Inf, Inf, Inf),
            method="L-BFGS-B")
theta_1 = fit$par
theta_1
p = theta_1[1]
a = theta_1[2]
s = theta_1[3]
mu = theta_1[4]
sigma = theta_1[5]
model_1 = p*dgamma(x, shape = a, scale = s) + (1-p)*dnorm(x, mean = mu, sd = sigma)
aic_1 <- 2*5 + 2*neg_log_likelihood(theta_1, x)
# hist(x, xlab = 'waiting', probability = T, col='pink', main='')
# lines(x, model_1)
```

```{r}
# model 2
p <- length(x[x<65])/length(x)
as_1 <- mean(x[x<65])
ass_1 <- var(x[x<65])
s_1 <- ass_1/as_1
a_1 <- as_1/s_1
as_2 <- mean(x[x>=65])
ass_2 <- var(x[x>=65])
s_2 <- ass_2/as_2
a_2 <- as_2/s_2
theta_inital <- c(p, a_1, s_1, a_2, s_2)
neg_log_likelihood <- function(theta, data){
  n <- length(data)
  
  p <- theta[1]
  a_1 <- theta[2]
  s_1 <- theta[3]
  a_2 <- theta[4]
  s_2 <- theta[5]
  
  l <- 0
  for (i in 1:n) {
    l = l + log(p*dgamma(data[i], shape = a_1, scale = s_1) + (1-p)*dgamma(data[i], shape = a_2, scale = s_2))
  }
  return(-l)
}
fit = optim(theta_inital,
            neg_log_likelihood,
            data = x,
            control = list(maxit = 1500),
            lower = c(0, 0, 0, 0, 0),
            upper = c(1, Inf, Inf, Inf, Inf),
            method="L-BFGS-B")
theta_2 <- fit$par
theta_2
p <- theta_2[1]
a_1 <- theta_2[2]
s_1 <- theta_2[3]
a_2 <- theta_2[4]
s_2 <- theta_2[5]
model_2 <- p*dgamma(x, shape = a_1, scale = s_1) + (1-p)*dgamma(x, shape = a_2, scale = s_2)
aic_2 <- 2*5 + 2*neg_log_likelihood(theta_2, x)
# hist(x, xlab = 'waiting', probability = T, col='pink', main='')
# lines(x, model_2)
```

```{r}
# model 3
p <- length(x[x<65])/length(x)
m_1 <- mean(x[x<65])
v_1 <- var(x[x<65])
sigma2_1 <- log((v_1/m_1^2) + 1)
mu_1 <- log(m_1) - sigma2_1/2
m_2 <- mean(x[x>=65])
v_2 <- var(x[x>=65])
sigma2_2 <- log((v_2/m_2^2) + 1)
mu_2 <- log(m_2) - sigma2_2/2
theta_inital <- c(p, mu_1, sqrt(sigma2_1), mu_2, sqrt(sigma2_2))
neg_log_likelihood <- function(theta, data) {
  n <- length(data)
  
  p <- theta[1]
  mu_1 <- theta[2]
  sigma_1 <- theta[3]
  mu_2 <- theta[4]
  sigma_2 <- theta[5]
  
  l <- 0
  for (i in 1:n) {
    l = l + log(p*dlnorm(data[i], meanlog = mu_1, sdlog = sigma_1) + (1-p)*dlnorm(data[i], meanlog = mu_2, sdlog = sigma_2))
  }
  
  return(-l)
}
fit = optim(theta_inital,
            neg_log_likelihood,
            data = x,
            control = list(maxit = 1500),
            lower = c(0, -Inf, 0, -Inf, 0),
            upper = c(1, Inf, Inf, Inf, Inf),
            method="L-BFGS-B")
theta_3 <- fit$par
theta_3
p <- theta_3[1]
mu_1 <- theta_3[2]
sigma_1 <- theta_3[3]
mu_2 <- theta_3[4]
sigma_2 <- theta_3[5]
model_3 <- p*dlnorm(x, meanlog = mu_1, sdlog = sigma_1) + (1-p)*dlnorm(x, meanlog = mu_2, sdlog = sigma_2)
aic_3 <- 2*5 + 2*neg_log_likelihood(theta_3, x)
# hist(x, xlab = 'waiting', probability = T, col='pink', main='')
# lines(x, model_3)
```

```{r}
hist(x, xlab = 'waiting', probability = T, col='yellow', main='')
lines(x, model_1, col = "red")
lines(x, model_2, col = "blue")
lines(x, model_3, col = "green")
```

```{r}
results <- data.frame(
  models = c("Gamma + Normal", "Gamma + Gamma", "Lognormal + Lognormal"),
  AIC = c(aic_1, aic_2, aic_3)
)
results
```





# Question 4

```{r}
gaussian <- function(vec)
{
  b0 <- vec[1]
  b1 <- vec[2]
  sigma <- vec[3]
  loglike <- 0
  for (i in 1:n row(Insurance))
  {
    loglike <- loglike + dnorm(Insurance$Claims[i],mean=avg, sd=sigma, log=TRUE)
    avg <- b0 + b1*Insurance$Holders[i] 
  }
  return(-1*loglike)
}
bic <- function(mle, parameters, data)
{
  N <- length(data)
  return((length(parameters))log(N)-2(mle$value))
}
gauss.est <- optim(c(0,1/5,1), gaussian)
gauss.bic <- bic(gauss.est, gauss.est$par, Insurance)
cat("The Gaussian BIC is:",Â gauss.bic)
```


```{r}
loglap <- function(x, mu, b)
{
  deno <- 2*b
  num <- exp(-abs(x-mu)/b)
  laplace <- num/deno
  return(log(laplace))
}
laplacian <- function(vec)
{
  b0 <- vec[1]
  b1 <- vec[2]
  sigma <- vec[3]
  loglike <- 0
  for (i in 1:nrow(Insurance))
  {
    avg <- b0 + b1*Insurance$Holders[i]
    loglike <- loglike + loglap(Insurance$Claims[i],mu=avg, b=sigma)
  }
  return(-1*loglike)
}
laplac.est <- optim(c(0, 0, 1), laplacian)
laplace.bic <- bic(laplac.est, laplac.est$par, Insurance)
cat("The Laplacian BIC is:",Â laplac.bic)

```


```{r}
lognorm <- function(vec)
{
  b0 <- vec[1]
  b1 <- vec[2]
  sigma <- vec[3]
  loglike <- 0
  for (i in 1:nrow(Insurance))
  {
    if (Insurance$Claims[i] > 0)
    {
      avg <- b0 + b1*Insurance$Holders[i]
      loglike <- loglike + dlnorm(Insurance$Claims[i], meanlog=avg, sdlog=sigma, log=TRUE)
    }
  }
  return(-1*loglike)
}
lognorm.est <- optim(c(0, 0, 1), lognormal)
lognorm.bic <- bic(lognorm.est, lognorm.est$par, Insurance)
cat("The Lognormal BIC is:",Â lognorm.bic)

```


```{r}
gamma.mod <- function(vec)
{
  b0 <- vec[1]
  b1 <- vec[2]
  sigma <- vec[3]
  loglike <- 0
  for (i in 1:nrow(Insurance))
  {
    if (Insurance$Claims[i] > 0)
    {
      avg <- b0 + b1*Insurance$Holders[i]
      loglike <- loglike + dgamma(Insurance$Claims[i], shape=avg, scale=sigma, log=TRUE)
    }
  }
  return(-1*loglike)
}
gamma.est <- optim(c(0,1/5,1), gamma.mod)
gamma.bic <- bic(gamma.est, gamma.est$par, Insurance)
cat("The Gamma BIC is:",Â gamma.bic)
```




## Problem 5

```{r echo=FALSE, include=FALSE}
library(ggplot2)

```




Following piece of code download the prices of TCS since 2007

```{r echo=TRUE, warning=FALSE}
library(quantmod)
getSymbols('TCS.NS')
tail(TCS.NS)
```

Plot the adjusted close prices of TCS

```{r warning=FALSE}
print(nrow(TCS.NS$TCS.NS.Adjusted))
plot(TCS.NS$TCS.NS.Adjusted)
```

**Download the data of market index Nifty50**. The Nifty 50 index
indicates how the over all market has done over the similar period.

```{r echo=TRUE, warning=FALSE}
getSymbols('^NSEI')
tail(NSEI)
```

Plot the adjusted close value of Nifty50

```{r}
plot(NSEI$NSEI.Adjusted)
```

### Log-Return

We calculate the daily log-return, where log-return is defined as $$
r_t=\log(P_t)-\log(P_{t-1})=\Delta \log(P_t),
$$ where $P_t$ is the closing price of the stock on $t^{th}$ day.

```{r}
TCS_rt = diff(log(TCS.NS$TCS.NS.Adjusted))
Nifty_rt = diff(log(NSEI$NSEI.Adjusted))
retrn = cbind.xts(TCS_rt,Nifty_rt)
retrn = na.omit(data.frame(retrn))
plot(retrn$NSEI.Adjusted,retrn$TCS.NS.Adjusted
      ,pch=20
      ,xlab='Market Return'
      ,ylab='TCS Return'
      ,xlim=c(-0.18,0.18)
      ,ylim=c(-0.18,0.18))
grid(col='grey',lty=1)
```

-   Consider the following model:

$$
r_{t}^{TCS}=\alpha + \beta r_{t}^{Nifty} + \varepsilon
$$ where $\mathbb{E}(\varepsilon)=0$ and
$\mathbb{V}ar(\varepsilon)=\sigma^2$.

### Sub-problem 1

> Estimate the parameters of the models $\theta=(\alpha,\beta,\sigma)$
> using the method of moments type plug-in estimator discussed in the
> class.


### Solution:


#### Introduction to calculations on the Method of Moments

We know, $i^{th}$ Moment of variable $X$,

$$
M_{i}=\frac{1}{n}\sum_{k=1}^{n}X_{k}^{i}
$$

##### Calculating Expectation by Method of Moments:


$$
\mathbb{E}(X)=M_{1}=m_{1}=\frac{1}{n}\sum_{i=1}^{n}X_{i}
$$


After simplifying, we get `equation (1)`

\begin{equation}
\mathbb{E}(X)=M_{1}=\overline{X} \tag{equation 1}
\end{equation}

##### Calculating Variance using Method of Moments:


\begin{align*}
\mathbb{E}(X^{2})&=M_{2}=m_{2}=\frac{1}{n}\sum_{i=1}^{n}X_{i}^{2} \\
\implies \mathbb{V}ar(X)+(\mathbb{E}(X))^{2}&=M_{2}=\overline{X^{2}} \\
\implies
\mathbb{V}ar(X)&=M_{2}+(\mathbb{E}(X))^{2}=\overline{X^{2}}+(\mathbb{E}(X))^{2}
\end{align*}


After replacing from `equation (1)`, we get,

\begin{equation}
\mathbb{V}ar(X)=M_{2}+M_{1}^{2}=\overline{X^{2}}+\overline{X}^{2} \tag{\text{equation(2)}}
\end{equation}


#### Solution Approach


##### First Moment:

We have already seen that the Expectation and First
moment of a random variable is the same.

```{r}
r_nif_mean = mean(retrn$NSEI.Adjusted)
r_tcs_mean = mean(retrn$TCS.NS.Adjusted)
```

Thus, $\mathbb{E}(r^{Nifty})=$ `r r_nif_mean` and  $\mathbb{E}(r^{TCS})=$
`r r_tcs_mean`

##### Second Moment:

```{r}
r_nif_second_mom = mean(retrn$NSEI.Adjusted ** 2)
r_tcs_second_mom = mean(retrn$TCS.NS.Adjusted ** 2)
```

$\mathbb{E}(({r^{Nifty}})^2)=$ `r r_nif_second_mom` and
$\mathbb{E}(({r^{TCS}})^2)=$ `r r_tcs_second_mom`


##### Calculation of Variance:


```{r}
r_nif_variance = r_nif_second_mom + r_nif_mean ** 2
r_tcs_variance = r_tcs_second_mom + r_tcs_mean ** 2
```

Since we already have calculated the First and the Second moment for both the
variable, we can calculate the Variance using the `equation (2)`.

$\mathbb{V}ar(r^{TCS}) = \mathbb{E}{(({r^{TCS}})^2)} +
(\mathbb{E}(r^{TCS}))^{2}=$ `r r_tcs_variance`

and

$\mathbb{V}ar(r^{Nifty}) = \mathbb{E}{(({r^{Nifty}})^2)} +
(\mathbb{E}(r^{Nifty}))^{2}=$ `r r_nif_variance`


##### Forming equations between parameters:
<br>
**Using the property of Expectation on the given model, we obtain `equation
(3)`**


\begin{equation}
\mathbb{E}(r^{TCS}) &= \mathbb{E}(\alpha + \beta r^{Nifty} +
\varepsilon) \\
\Rightarrow &\mathbb{E}(r^{TCS}) &= \alpha + \beta*\mathbb{E}(r^{Nifty})
+ \mathbb{E}(\varepsilon) \\
\Rightarrow &\mathbb{E}(r^{TCS}) &= \alpha + \beta*\mathbb{E}(r^{Nifty})
~~~[\because \mathbb{E}(\varepsilon) = 0] \tag{\text{equation (3)}}  
\end{equation}


Therefore putting values of $\mathbb{E}(r^{TCS})$ and
$\mathbb{E}(r^{Nifty})$ in `equation (3)` we get `equation (4)`


$\alpha +$ `r r_nif_mean` $\beta=$ `r r_tcs_mean`$\hspace{6mm}\text{equation (4)}$


**On multiplying explanatory variable $r^{Nifty}$ on both sides of the
model, we obtain,**


$$
r^{TCS} r^{Nifty} = \alpha r^{Nifty} + \beta (r^{Nifty})^{2} +
\varepsilon r^{Nifty}
$$


Now, using the property of Expectation on the above equation we obtain `equation
(5)`,


\begin{equation}
\mathbb{E}(r^{TCS} r^{Nifty}) &= \mathbb{E}(\alpha r^{Nifty} + \beta
(r^{Nifty})^{2} + \varepsilon r^{Nifty}) \\
\implies \mathbb{E}(\alpha r^{Nifty}) + \mathbb{E}(\beta
(r^{Nifty})^{2}) &= \mathbb{E}(r^{TCS} r^{Nifty}) -
\mathbb{E}(\varepsilon r^{Nifty}) \\
\implies \alpha\mathbb{E}(r^{Nifty}) +
\beta\mathbb{E}((r^{Nifty})^{2}) - \mathbb{E}(r^{TCS} r^{Nifty}) &=
\mathbb{E}(r^{TCS} r^{Nifty}) \tag{\text{equation (5)}}
\end{equation}


```{r}
tcs_nif_prod_mean = mean(retrn$TCS.NS.Adjusted * retrn$NSEI.Adjusted)
```

Replacing, expected values in the above equation we get, `equation (6)`


$\bullet~$ `r r_nif_mean` $\alpha+$ `r r_nif_second_mom` $\beta=$
`r tcs_nif_prod_mean` $\hspace{6mm} \text{equation (6)}$


**Applying property of Variance on the given model, we get `equation
(7)`**


\begin{align*}
\mathbb{V}ar(r^{TCS}) &= \mathbb{V}ar(\alpha + \beta r^{Nifty} +
\varepsilon) \\
\Rightarrow \mathbb{V}ar(r^{TCS})&=\mathbb{V}ar(\beta * r^{Nifty}) +
\mathbb{V}ar(\varepsilon) \\
\Rightarrow \mathbb{V}ar(r^{TCS})&=\beta^{2} * \mathbb{V}ar(r^{Nifty}) +
\sigma^{2} ~~~[\because \mathbb{V}ar(\varepsilon) = \sigma^{2}] & \dots
\text{equation (7)}
\end{align*}


Therefore putting values of $\mathbb{V}ar(r^{TCS})$ and
$\mathbb{V}ar(r^{Nifty})$ in `equation (7)`, we get `equation (8)`


$~~~~~~~\bullet~$ `r r_nif_variance` $\beta^{2}+\sigma^{2}=$ `r r_tcs_variance`
$~~~~~~~~~~~~~~~~~~\dots \text{equation (8)}$


#### Solving for values of the parameters

<br>
`equation (4)`

> $\alpha +$ `r r_nif_mean` $\beta=$ `r r_tcs_mean`
`equation (6)`

> `r r_nif_mean` $\alpha+$ `r r_nif_second_mom` $\beta=$ `r
> tcs_nif_prod_mean`
`equation (8)`

> `r r_nif_variance` $\beta^{2}+\sigma^{2}=$ `r r_tcs_variance`

- Solving `equation (4)` & `(6)` we get the values of parameters
$\alpha$ & $\beta$
- Now putting the solved value of $\beta$ into `equation (8)` we get the
value of $\sigma$

```{r echo=TRUE}
A = rbind(c(1, r_nif_mean), c(r_nif_mean, r_nif_second_mom))
B = c(r_tcs_mean, tcs_nif_prod_mean)
values = solve(A,B)
alpha_mm = values[1]; beta_mm = values[2]
sigma_mm = (r_tcs_variance - (r_nif_variance*(beta_mm**2)))**0.5
paste('alpha=',alpha_mm,'; beta=',beta_mm,'; sigma=',sigma_mm)
```



**Estimated values of the parameters are in the following table of
Problem 3**


### Sub-problem 2


> Estimate the parameters using the `lm` built-in function of `R`. Note
> that `lm` using the OLS method.

### Solution:


Given Model,

$$
r_{t}^{TCS}=\alpha + \beta r_{t}^{Nifty} + \varepsilon
$$

Here, in the model $r_{t}^{TCS}$ is the target or dependent variable and
$r_{t}^{Nifty}$ is the explanatory variable. Also, $\alpha$ is the
co-efficient and $\beta$ is slope of the linear model.

- From the **Model Coefficients** of the `model` object derived from
`lm` function, we get the values of intercept($\alpha_{lm}$) and the
slope($\beta_{lm}$). After that, we can predict the values of the target
variable with the help of derived parameters.

where,

- Predicted value of the TCS stock,
$r_{pred}^{TCS}=\alpha_{lm}+\beta_{lm}*r_{actual}^{Nifty}$

- Error in prediction, $\varepsilon=r_{pred}^{TCS}-r_{actual}^{TCS}$

```{r echo=TRUE}
model = lm(TCS.NS.Adjusted ~ NSEI.Adjusted, data = retrn)
alpha_ols = model$coefficients[[1]]
beta_ols = model$coefficients[[2]]
retrn$r_tcs_predicted = model$fitted.values
retrn$error = retrn$r_tcs_predicted - retrn$TCS.NS.Adjusted
sigma_ols = sd(retrn$error)
paste('alpha=',alpha_ols,'; beta=',beta_ols,'; sigma=',sigma_ols)
```

**Estimated values of the parameters are in the following table of
Problem 3**


### Sub-problem 3


> Fill-up the following table
| Parameters | Method of Moments |        OLS      |
|------------|-------------------|-----------------|
| $\alpha$   |  `r alpha_mm`     |  `r alpha_ols`  |
| $\beta$    |  `r beta_mm`      |  `r beta_ols`   |
| $\sigma$   |  `r sigma_mm`     |  `r sigma_ols`  |


### Sub-problem 4


> If the current value of Nifty is 18000 and it goes up to 18200. The
> current value of TCS is Rs. 3200/-. How much you can expect TCS price
> to go up?

### Solution:


```{r echo=TRUE}
nif_current = 18000
nif_future = 18200
tcs_current = 3200
nif_return = log(nif_future) - log(nif_current)
tcs_return_pred = predict(model, data.frame(NSEI.Adjusted =
c(nif_return)))
tcs_forecast = round(exp(tcs_return_pred) * tcs_current)
paste('TCS forecasted value:',tcs_forecast)
```

**After prediction by the model, we can say TCS stock price would go up
to `r tcs_forecast
